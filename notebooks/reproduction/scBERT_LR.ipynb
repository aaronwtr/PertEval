{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf761f8a",
   "metadata": {},
   "source": [
    "Simplified version of https://github.com/clinicalml/sc-foundation-eval/blob/main/scBERT/scbert_baselines_LR.ipynb\n",
    "\n",
    "SAMPLING_FRACS determines the fraction of the training data on which to train\n",
    "(the paper shows that logistic regression outperforms scBERT even for small fractions)\n",
    "NREPS determines number of splits\n",
    "\n",
    "If sampling_frac is 1 then NREPS should be 1, otherwise we just get repeated runs\n",
    "on the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236d552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read Zheng data. download \n",
    "zheng_data = sc.read_h5ad(\"/data/scBERT/Zheng68K.h5ad\")\n",
    "zheng_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58e32b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = zheng_data.X\n",
    "label = zheng_data.obs.celltype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d0fc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NREPS = 1\n",
    "SAMPLING_FRACS = [1.0]\n",
    "\n",
    "ks = []\n",
    "fracs = []\n",
    "cs=[]\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "test_f1s = []\n",
    "for k in np.arange(NREPS):\n",
    "    for frac in SAMPLING_FRACS:\n",
    "        ks.append(k)\n",
    "        fracs.append(frac)\n",
    "        print(\"frac {}, rep {}\".format(frac, k))\n",
    "        #downsample training set\n",
    "        sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=2022) #update Aug 2023: hold train/val across all runs #same train/val set split for each frac in k\n",
    "        for index_train, index_val in sss.split(data, label):\n",
    "            np.random.seed(k)\n",
    "            index_train_small = np.random.choice(index_train, round(index_train.shape[0]*frac), replace=False)\n",
    "            X_train, y_train = data[index_train_small], label[index_train_small]\n",
    "            X_test, y_test = data[index_val], label[index_val]\n",
    "\n",
    "        print(\"Loaded data...\")\n",
    "\n",
    "        #train on train_dataset\n",
    "        \n",
    "        \"\"\" c=0.1 was always best, using going forward without always running tuning\n",
    "        #hyperparameter tune using k-fold val on training data\n",
    "        cv_results = {}\n",
    "        for c in [1e-3, 1e-2, 1e-1, 1]:\n",
    "            print(\"c={}\".format(c))\n",
    "            lr = LogisticRegression(random_state=0, penalty=\"l1\", C=c, solver=\"liblinear\")\n",
    "            res = cross_validate(lr, X_train, y_train, scoring=['accuracy'])\n",
    "            cv_results[c] = np.mean(res['test_accuracy'])\n",
    "        print(cv_results)\n",
    "\n",
    "        #choose best c and calc performance on val_dataset\n",
    "        best_ind = np.argmax(list(cv_results.values()))\n",
    "        c = list(cv_results.keys())[best_ind]\n",
    "        cs.append(c)\n",
    "        \"\"\"\n",
    "        c = 0.1\n",
    "        #print(\"best c={}\".format(c))\n",
    "        lr = LogisticRegression(penalty=\"l1\", C=c, solver=\"liblinear\") #random_state=0, \n",
    "        lr.fit(X_train, y_train)\n",
    "        train_acc = lr.score(X_train, y_train)\n",
    "        test_acc = lr.score(X_test, y_test)\n",
    "        print(\"train set accuracy: \" + str(np.around(train_acc, 4)))\n",
    "        print(\"test set accuracy: \" + str(np.around(test_acc, 4)))\n",
    "        val_macro_f1 = f1_score(y_test, lr.predict(X_test), average=\"macro\")\n",
    "        print(\"test set macro F1: \" + str(np.around(val_macro_f1, 4)))\n",
    "        train_accs.append(train_acc)\n",
    "        test_accs.append(test_acc)\n",
    "        test_f1s.append(val_macro_f1)\n",
    "        \n",
    "        print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
